import { pipeline } from "@huggingface/transformers";
import { parquetRead } from "hyparquet";
import { compressors } from "hyparquet-compressors";
import path from "path";
import fs from "fs";
import { performance } from "perf_hooks";

// ==============================================================================
// 1. ì„¤ì •: ê²½ë¡œ ë° ëª¨ë¸
// ==============================================================================
const PARQUET_FILE_PATH = path.join("data", "ipi", "sampled_benchmark_1000.parquet");
const MODEL_NAME = "Xenova/all-MiniLM-L6-v2";

async function loadParquetData(filePath: string): Promise<string[]> {
    console.log(`ğŸ“‚ Parquet íŒŒì¼ ì½ëŠ” ì¤‘: ${filePath}`);

    if (!fs.existsSync(filePath)) {
        throw new Error(`âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${filePath}\n   ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.`);
    }

    const buffer = fs.readFileSync(filePath);
    const arrayBuffer = buffer.buffer.slice(buffer.byteOffset, buffer.byteOffset + buffer.byteLength);

    return new Promise((resolve, reject) => {
        parquetRead({
            file: arrayBuffer,
            compressors: compressors,
            onComplete: (data: any) => {
                // [ìˆ˜ì • í¬ì¸íŠ¸]
                // dataê°€ ë°°ì—´(Array)ì¸ ê²½ìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
                // ì˜¤ë¥˜ ë¡œê·¸ì˜ "0, 1, 2..."ëŠ” dataê°€ í–‰(Row)ë“¤ì˜ ë°°ì—´ì´ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤.

                const texts: string[] = [];

                if (Array.isArray(data)) {
                    // ë°ì´í„°ê°€ ë°°ì—´(í–‰ ë¦¬ìŠ¤íŠ¸)ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
                    console.log(`ğŸ” ${data.length}ê°œì˜ í–‰(Row)ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.`);

                    for (const row of data) {
                        // ê° í–‰ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                        // ë°°ì—´ í˜•íƒœì¼ ìˆ˜ë„ ìˆê³ , ê°ì²´ í˜•íƒœì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ì²´í¬
                        let val = null;
                        if (typeof row === 'object' && row !== null) {
                            val = row.text || row.instruction || row.content || row.prompt || row[0];
                        }

                        if (val) texts.push(String(val));
                    }
                } else {
                    // ê¸°ì¡´ ë¡œì§: ë°ì´í„°ê°€ ì»¬ëŸ¼ ì¤‘ì‹¬ ê°ì²´ì¸ ê²½ìš° ({ text: [...], label: [...] })
                    const columns = Object.keys(data);
                    const textColumn = columns.find(col =>
                        ['text', 'instruction', 'content', 'prompt'].includes(col)
                    );

                    if (textColumn && Array.isArray(data[textColumn])) {
                        texts.push(...data[textColumn].map(String));
                    }
                }

                if (texts.length > 0) {
                    console.log(`âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: ${texts.length}ê±´`);
                    resolve(texts);
                } else {
                    reject(new Error(`âŒ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`));
                }
            }
        }).catch((err) => {
            reject(new Error(`âŒ Parquet íŒŒì‹± ì‹¤íŒ¨: ${err.message}`));
        });
    });
}

async function runBenchmark() {
    console.log("\nğŸš€ [Real Data Embedding Benchmark] Node.js + ONNX (hyparquet)");
    console.log("==============================================================");

    // 1. ë°ì´í„° ë¡œë“œ
    let samples: string[] = [];
    try {
        samples = await loadParquetData(PARQUET_FILE_PATH);
    } catch (e: any) {
        console.error(e.message);
        console.log("âš ï¸ ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.");
        samples = Array(100).fill("This is a dummy sentence for benchmarking.");
    }

    if (samples.length === 0) return;

    // 2. ëª¨ë¸ ë¡œë”©
    console.log(`\nâ³ ëª¨ë¸ ë¡œë”© ì¤‘: ${MODEL_NAME}...`);
    const extractor = await pipeline("feature-extraction", MODEL_NAME, {
        quantized: true,
    });
    console.log("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!");

    // 3. Warm-up
    console.log("ğŸ”¥ ì›œì—… (Warm-up)...");
    await extractor(samples[0], { pooling: "mean", normalize: true });

    // 4. ì¸¡ì • ì‹œì‘
    console.log(`\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ (ì´ ${samples.length}ê±´)...`);

    const latencies: number[] = [];
    const startTotal = performance.now();

    for (let i = 0; i < samples.length; i++) {
        const start = performance.now();
        await extractor(samples[i], { pooling: "mean", normalize: true });
        const end = performance.now();

        latencies.push(end - start);

        if ((i + 1) % 100 === 0) process.stdout.write(".");
    }
    const endTotal = performance.now();
    console.log("\n");

    // 5. ê²°ê³¼ ê³„ì‚°
    const totalTime = endTotal - startTotal;
    const avg = latencies.reduce((a, b) => a + b, 0) / latencies.length;
    const min = Math.min(...latencies);
    const max = Math.max(...latencies);

    // P99 ê³„ì‚°
    const sorted = [...latencies].sort((a, b) => a - b);
    const p95 = sorted[Math.floor(latencies.length * 0.95)];
    const p99 = sorted[Math.floor(latencies.length * 0.99)];

    console.log("\nğŸ† [ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸ - Node.js ì‹¤ì¸¡]");
    console.log(`----------------------------------------`);
    console.log(`ë°ì´í„° ìˆ˜       : ${samples.length} ê°œ`);
    console.log(`ì´ ì†Œìš” ì‹œê°„    : ${(totalTime / 1000).toFixed(2)} ì´ˆ`);
    console.log(`----------------------------------------`);
    console.log(`Average Latency : ${avg.toFixed(2)} ms  ğŸ‘ˆ (ë³´ê³ ì„œìš© ìˆ˜ì¹˜)`);
    console.log(`Min Latency     : ${min.toFixed(2)} ms`);
    console.log(`Max Latency     : ${max.toFixed(2)} ms`);
    console.log(`P95 Latency     : ${p95.toFixed(2)} ms`);
    console.log(`P99 Latency     : ${p99.toFixed(2)} ms`);
    console.log(`----------------------------------------`);
}

runBenchmark();